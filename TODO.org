
* Thesis Statement
The software consists of three services:
** Order Placement Engine
*** performs
offer placement in a market according to provided guidelines
*** receives guidelines as
a set of numerical parameters representing
**** risk tolerances,
**** hedging requirements,
**** profit targets
**** a market sentiment, defined as
***** interpretations of past market events
***** policies for interpreting current market events
***** expectations regarding future market events
** Market Observer
tool for evaluating statistical queries on market events, past and present
** Network                                                             :WIP:
decentralized multimodal swarm optimization of the above guidelines
* Overview of Current Capabilities
** what it is / how it acts
*** acts upon an exchange account
**** loss-aversion implemented for spot exchanges
**** rudimentary loss-aversion for leveraged trading
*** configurable parameters for offer distribution:
**** resilience - how deep into the orderbook to place offers
**** targeting - what allocation is targeted by the relative buy/sell sizes
**** fund - what proportion of assets is placed on the order book at once
**** profitability relative to past execution
** what it should be
*** forget about machine optimization
*** strive for Augmented Interaction
* Book Filter
** TODO replace pull system with pushed depth updates
** TODO experiment with clustering
there are at least three (3) reasons for this, consisting of only one (1!) bad
reason, and two good reasons (2!)
1. it's more fun to write algorithms rather than refactoring the plumbing
2. clustering the market functions as rudimentary reduction of offer noise
3. noise reduction before numerical weightlifting is not premature optimization
** DONE Pulls order book updates from a book-tracker
Currently these are simply entire books, but depth updates would be best.
** DONE Pulls offer status updates from a supplicant
Offer placement and offer cancellation
** DONE Support multiple filters on a single book
* TODO refactor scalar value representations, to include units
bitfinex and btce give volume in primary, always; kraken can do either
** DONE taken,given - asset×quantity
** DONE add markets to asset registry, so we can represent prices?
*** differentiate buy vs sell via sign bit - works with current price scalars
*** no need for a separate registry if assets and markets count together
** TODO create give/take directly in each exchange API
** TODO consider imod*exp(jarg) instead of ix+jy
this can still be precise for gaussian integers of sufficiently low entropy.
* TODO Basis Tracking
bastard child from the unholy marriage of balance and execution tracking
** TODO recursive cost basis:
link the cost basis which was traded away for acquiring the asset. memory
requirement becomes linear wrt execution (is currently sub-linear, if not
constant), although the constant factor is minor compared to other memory hogs
** TODO leverage basis
generalize the current system, which is hardcoded for a specific exchange
** DONE account for exchange fees
use net-cost/volume / given/taken-asset/amount rather than the raw
exchange-reported cost/volume/price
** DONE track cost basis for all "virtual outputs" in an account
*** "virtual output" is an asset×quantity earned from a trade
*** funds that haven't yet been traded - don't have a cost basis
*** there are never more cost bases than funds in an account
*** shallow cost basis = ( market×price asset×quantity asset×quantity )
aq2 is just (aq* mp aq1)
** DONE updating bases sets upon execution
*** remove old cost basis from given asset×quantity
*** add new cost basis from taken-asset×quantity and old cost basis
*** FIFO/LIFO - what are the considerations?
**** currently, we use LIFO: most recent cost basis gets consumed
**** CIFO - cheapest-in first-out: consume the least profitable
so we have more flexibility against future swings
** DONE print-book pair-basis
a method exists! although, it could use improvement.
* TODO evolve spreader
** DONE spread candidate target offers by profit from bases
*** currently, profitability is checked/attempted:
**** in ope-filter
**** against the entire buy/sell history
*** requires basis tracking for the Right Thing™
*** cumulative comparison of
- candidate targets and
- executed bases
** TODO epsilon flexibility based on target skew
** TODO consume multiple fundcuts
* TODO Cleanup TODO.org
because no meeter is complete without its stfu
* TODO Precision
** DONE Switch to CL-JSON
for full control of float parsing, rather than ST-JSON's default to #'READ
** TODO Eradicate floats from all price calculations
all price manipulation must be done on integer values! this should already
be the case, but do a line-by-line audit just to be 100% certain
*** TODO actor.lisp
how did this file even end up in this list!?
*** TODO exchange.lisp
*** TODO individual exchanges
**** TODO bit2c.lisp
**** TODO bitfinex.lisp
**** TODO bitmex.lisp
**** TODO btce.lisp
**** TODO kraken.lisp
**** TODO mpex.lisp
*** TODO db.lisp
for all practical purposes, this file does not yet exist, nor should it.
*** TODO qd.lisp
*** TODO util.lisp
** TODO Replace scalars with asset-quantity where appropriate
a bit of an endeavor, but will be worthwhile. required for proper level2 depth!
** TODO Eradicate floats from EVERY SINGLE calculation
using floats for statistics is tolerable, but we can do better!
* TODO normalize rawness convention
** current status
*** some methods take string arguments
*** some take values and adapt them - fix these!
** desired behavior
any method with "raw" in its name, such as post-raw-limit:
*** receives literal parameters, get inserted as-is to API requests
*** returns json object of exchange's response
* TODO Names Abstraction                                            :OVERDUE:
** example: exchanges, assets, markets, bots (INCLUDING actors!)
** aspects to flesh out
*** TODO class metaclass for named instance classes
*** TODO generic function metaclass for named dispatch
*** TODO registered (symbol?) vs unregistered (string?) names
* TODO Actor Abstraction
CSP×FSM
** philosophy of crash-only design
it should be possible to kill an actor's thread at any time, and spawning the
actor's run-function again in the proper manner should resume the actor's functioning
*** initialization
**** customization of initialization
initialization specs for actors should be defined as methods on one or more of
initialize-instance, reinitialize-instance, or shared-initialize
**** default initialization
***** channels
creation of all channels necessary for the actor's functioning
 - input channels
 - broadcast channels
 - control channels - is this just a subtype of input?
right now let's create channels as early as possible, ie, :initform
***** execution
of the actor's state machine must be insured, possibly by
 - spawning a new thread for this purpose, or
 - adding a task to an execution pool
***** registration with watchdog
the new actor provides the watchdog a death predicate, and a check frequency.
** DONE MVP
** DONE factor out parent pattern
*** initialize based on appropriate parent initargs
*** supervise during parent operation
*** reinitialize
** TODO support symbols as slot names for delegates and children
elaborate on this, since it appears to already exist...
** TODO fetcher pattern
*** TODO should not use #'sleep
*** TODO needs separate actor, or can fetcher be just a task?
** TODO spammer pattern
- https://github.com/adlai/scalpl/blob/8c9f905/qd.lisp#L271-272
- https://github.com/adlai/scalpl/blob/8c9f905/qd.lisp#L302
** TODO protocols
*** TODO kill
*** TODO init
*** TODO reinit
** TODO method-combination chanl:select
an implementation already exists!
*** TODO build tests for prototype implementation
*** TODO specification, similarly to that of the select macro
*** TODO conforming implementation
** TODO initializaton race
** TODO compare memento-mori to actor.lisp https://github.com/zkat/memento-mori
*** TODO (set-difference actor memento-mori)
*** TODO (set-difference memento-mori actor)
** macro prototype
*** TODO sample
**** input - port current gate, as-is, to imagipony defactor macro
(defactor gate ()
  ((in :initform (make-instance 'chanl:channel))
   (key :initarg :key)
   (signer :initarg :secret)))
**** sample output
** implementation data
*** machine definition
a Finite State Machine description of the actor's interaction with its channels
**** how it handles inputs
functions called on arguments received from each input
**** how it handles outputs
when it broadcasts, and what do the broadcasts contain
**** "Remote API"
i.e. how to 'control' this actor, alter its state machine, etc
*** channel(s) to which that actor listens
*** channel(s) to which that actor sends
** timing
should timing (ie, "update the order book every 8 seconds") be expressed in actors, or
is that something better left to abstract out as a separate service sending timed messages?
** TODO devtools
we'll need a cross-actor debugger / condition handler, and repl-like functionality
**** condition system
make the condition system and debugger function across threads, see cond.js
**** reflection / inspection
send a function to be applied to the actor (return handled by caller)
* TODO Portfolio Handling Guidelines
How the investor specifies guidelines to the automated market maker
** "risk tolerances"
how "deep" we ensure order flow profitability
** "hedging requirements"
how readily we lose balance and regain it
** "profit targets"
kinda maybe related to "risk tolerances"?
** "market sentiment"
this should perhaps be scrapped / merged into the swarm
* Exchange modularity
** Need to distinguish between:
*** knowing a market exists
(find-class 'market)
**** which assets are traded
(with-slots (primary counter) market ..)
**** at what precision
(decimals market)
**** TODO default fee structure
implicit in btce, make this explicit everywhere
*** TODO tracking a market
**** book tracker, current market depth
**** trades tracker, past market movements
**** TODO separate out 'online' calculations
*** participating in it
**** market + gate = ope ?
**** where does the supplicant fit in?
** Participation should be mediated by rate gates
* Account
** Contents:
*** exchange / gate object
**** executes commands
**** obeys rate limit
*** balance manager
**** tracks asset balances
**** handles hedging requirements and target exposures
**** reports asset balances
**** calculates liquidity allocation plan
*** offer manager
**** tracks open offers
**** routes limit orders and cancellations to the exchange
**** performs on-demand analysis on offer distributions
**** limit orders placement according to priority (ie "best" price)
*** command executor
**** translates limit orders and cancellations into API calls
**** filters out "EOrder:Insufficient funds" errors
(they'll get placed again next round)
*** offer execution tracker
**** downloads offer execution backlog
**** tracks execution of my offers
**** performs on-demand analysis on execution stream
***** emvwap, duplex and directional
***** order flow optimization
***** update offer handler
* Trades-Tracker
** Level 2 order book!
Think later of ways to do this efficiently, right now we're just interested in
the high-level so we can express statistical arbitrage rules
** Trade Direction
*** Some exchanges provide this information in the trades data
*** For exchanges that don't, we use a classifier:
**** continually tracks best few offers on the book
**** Was the last trade >= the lowest ask? -> buyer initiative
**** Was the last trade <= the highest bid? -> seller initiative
* Dumbot
** Resilience
*** Definition
How large a buy or sell we want to suvive without getting "run over"
*** Old definition - included for reference
Our buy resilience is 4BTC, we have 0.5BTC to sell, and the ask-side order book
looks like:
|     Price |     Volume |      Depth | Our Liquidity |
|-----------+------------+------------+---------------|
| 350.00000 | 0.05000000 | 0.05000000 |               |
| 350.02859 | 0.10000000 | 0.15000000 |               |
| 350.18932 | 0.87382719 |  1.0238272 |               |
| 350.71930 | 0.18990000 |  1.2137272 |               |
| 350.99999 | 0.15000000 |  1.3637272 |               |
| 351.00000 | 2.00000000 |  3.3637272 |               |
| 351.59920 | 0.39996200 |  3.7636892 |               |
We'd thus want to spread out our 0.5BTC between the best possible ask, and just
before the last ask with a depth less than our resilience. It should spread out
the orders proportionally to the depth necessary to reach each one -- thus, we
scale our available liquidity by the VOLUME AT each order,
beginning from the minimal order size (say, 0.001 BTC), and up as high as
possible. The overall goal is not to change the shape of the order book, just
increase its liquidity.
*** Resilience is now more complex
We should at least have separate resilience for each side of the order book, if
not even distinct levels of funds, each bound at different resilience levels.
*** TODO Resilience is not just depth
we should also have resilience based on percentage moves
** Inputs:
(for just one side of the algorithm)
*** Order book
*** Resilience
*** Funds
** TODO Pruning
because the best names are both stolen and inappropriate
*** receives target offers of unknown profitability
*** checks each offer against executions from the other side
*** unprofitable offers get modified to restore profitability
possible methods:
**** reduce offer size, in favor of subsequent one(s)
simpler, doesn't require inflection points
**** adjust offer price, and that of subsequent ones
best performed in relation to order book inflection points
* TODO de-brittlify nonces
** btce's nonce code will crap out on 2015-04-09
well, at least your date calculation was correct!
the better approach here would be tracking nonces per-key in gates, and incfing.
** bitfinex's is likely at some point to overflow and break hidden offers
